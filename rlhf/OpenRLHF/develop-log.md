# æ‰©å±• OpenRLHF çš„æ¨ç†å¼•æ“

ä¼—æ‰€å‘¨çŸ¥ï¼Œåœ¨å¾ˆé•¿ä¸€æ®µæ—¶é—´ï¼ŒOpenRLHF éƒ½ä»¥ vllm ä½œä¸ºä¸»è¦çš„æ¨ç†å¼•æ“ï¼Œè€Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå°† SGLang æ¥å…¥å…¶ä¸­ï¼Œæ‰€ä»¥è¿™ä¸ªæ—¥å¿—ä¸»è¦è®°å½•äº†è¿™ä¸€å¼€å‘å†ç¨‹ã€‚è™½ç„¶è¿™äº‹æƒ…å·²ç»åšäº†å¥½å‡ å‘¨äº†ï¼Œä½†çœŸçš„ä¸€è·¯éƒ½æ˜¯å¤§å‘ã€‚ä¹‹å‰åœ¨ SGLang ä¸‹è¸©è¿‡çš„å‘å·²ç»è¯¦ç»†é˜è¿°è¿‡äº†ï¼Œè¿™é‡Œ ref ä¸€ä¸‹ï¼š

- [Latency optimization for weight updates](./sglang/latency-accelerte-for-weight-updates/readme.md)ï¼šä¸€æ¬¡å¯¹æ•ˆç‡çš„ debug è¿‡ç¨‹ï¼ŒåŒæ ·åˆŠè½½äº[è®°ä¸€æ¬¡å¯¹ SGLang weight update latency çš„ä¼˜åŒ–](https://zhuanlan.zhihu.com/p/9908228168)ã€‚

## Quick Start

OpenRLHF çš„æ–‡æ¡£é»˜è®¤ç”¨æˆ·éƒ½æ¯”è¾ƒç†è§£ RLHF çš„æµç¨‹ï¼Œæ‰€ä»¥å¾ˆå¤šåœ°æ–¹å†™çš„ä¸ç®—å…¥é—¨ï¼Œå¯¹æˆ‘è¿™ç§ä¸ç”šç†è§£ RLHF çš„äººå°±æ¯”è¾ƒç—›è‹¦ï¼Œä»…ä»…è·‘èµ·æ¥å°±é‡åˆ°äº†ä¸å°‘å‘ã€‚

### é…ç¯å¢ƒ

æˆ‘ä¸€å¼€å§‹è¯¯åˆ¤äº† OpenRLHF çš„ä¾èµ–å¤æ‚åº¦ï¼ŒçŒœæµ‹åº”è¯¥éå¸¸é«˜ï¼Œæ‰€ä»¥é€‰æ‹©äº† dockerã€‚äº‹åå‘ç°ï¼Œå…¶å®åªæ˜¯éœ€è¦ deepspeed vllm å’Œ openrlhf åœ¨ä¸€å—å„¿å°±è¡Œäº†ã€‚ä¸è¿‡ï¼Œè¿™é‡Œè¿˜æ˜¯åˆ†äº«ä¸‹æˆ‘è‡ªå·±ç”¨çš„ docker æŒ‡ä»¤ï¼š

```bash
docker run --runtime=nvidia -it --shm-size="40g" --cap-add=SYS_ADMIN   -v /opt/dlami/nvme/chenyang:/var/lib/docker   
nvcr.io/nvidia/pytorch:24.07-py3 bash
```

æˆ‘æŠŠ[åŸæ–‡æ¡£æŒ‡ä»¤](https://openrlhf.readthedocs.io/en/latest/quick_start.html#installation)é‡Œé¢çš„ `--rm` å»æ‰äº†ï¼Œä¸ç†è§£ä¸ºä»€ä¹ˆè¦åŠ è¿™ä¸ªå‚æ•°ï¼Œå¯¼è‡´ docker å®¹å™¨åœ¨é€€å‡ºåè‡ªåŠ¨åˆ é™¤ã€‚

è¿›å…¥ docker åï¼Œå…ˆå¸è½½ç¯å¢ƒé‡Œé¢çš„ä¸€äº›åº“ï¼Œé¿å…å’Œ OpenRLHF çš„ä¾èµ–å†²çªã€‚

```bash
pip uninstall xgboost transformer_engine flash_attn -y
```

ç„¶åï¼Œå®‰è£…æœ‰ vllm ä¾èµ–çš„ OpenRLHFã€‚

```bash
 pip install openrlhf[vllm]
```

è¿™ä¸ªå‘è¡Œç‰ˆå¯èƒ½å¶å°”ä¼šè¢«å–æ¶ˆï¼Œä¹Ÿå¯ä»¥ç›´æ¥å®‰è£…æœ€æ–°å‘è¡Œçš„ openrlhf å’Œ vllm çš„æŒ‡å®šç‰ˆæœ¬ï¼Œå‰è€…ç‰ˆæœ¬æ— æ‰€è°“ï¼Œåè€…å¾—ä» OpenRLHF çš„ä¾èµ–ä¸­æŸ¥æ‰¾æ‰€æ”¯æŒçš„ç‰ˆæœ¬ï¼Œæœ€æ–°çš„ vllm ä¸ä¸€å®šæ”¯æŒï¼Œæˆ‘æ˜¯ç”¨çš„æ˜¯ 0.6.4.post1ã€‚

ç”¨ docker çš„è¯ï¼Œæ¥ç€å¯ä»¥æŠŠ docker commit ä¿å­˜ä¸‹æ¥ï¼Œ`docker ps -a` æŸ¥æ‰¾ `<container_id>`ï¼Œç„¶å `docker commit <container_id> openrlhf_chenyang`ï¼Œä¸‹æ¬¡ç›´æ¥ `docker run --gpus all -it openrlhf_chenyang` å°±å¯ä»¥ç›´æ¥è¿›å…¥ docker äº†ã€‚

æœ€åé…ç½® `wandb`ï¼Œè€å®è¯´æˆ‘éƒ½æœ‰å¿«ä¸¤å¹´æ²¡ç¢°è¿‡è¿™ç©æ„å„¿äº†ï¼Œè¶Šå‘è§‰å¾—é™¤äº†ç›‘æ§è®­ç»ƒæ›²çº¿ä¹‹å¤–ï¼Œæ„ä¹‰ä¸å¤§ã€‚OpenRLHF å¯ä»¥åŸºäº ray ä½¿ç”¨ï¼Œè€Œ ray æœ‰ä¸€å¥—è‡ªå·± prometheus çš„ç›‘æ§ï¼Œå¯ä»¥ç›´æ¥ç”¨ ray dashboard æŸ¥çœ‹ logï¼Œå½“ç„¶ï¼Œè¦é…ç½® `wandb` ä¹Ÿä¸éº»çƒ¦ï¼Œ`wandb init` ä¸€é€šæ“ä½œå°±å¥½äº†ã€‚

### Quick Check Out

ç”±äºæˆ‘ä¸»è¦æ˜¯ä½¿ç”¨å•æœºå¤šå¡åš SGLang å’Œ vllm çš„å¯¹æ‹ï¼Œæ‰€ä»¥ä¸ä½¿ç”¨å¤šæœºæ¨¡å¼ã€‚è¿™é‡Œç®€å•ç»™ä¸¤ä¸ªæŒ‡ä»¤ï¼š

```bash
ray start --head --node-ip-address 127.0.0.1 --num-gpus 3 --port 4567 --temp-dir="/opt/dlami/nvme/chenyang/.cache/ray"
```

è¿™æ˜¯åœ¨å•æœºçš„ 3 å¼ å¡ä¸Šå¯åŠ¨ ray çš„ head èŠ‚ç‚¹ï¼Œå¯èƒ½ä¼šé‡åˆ°å„ç§å¯åŠ¨å¤±è´¥çš„æƒ…å†µï¼Œè¯¸å¦‚ç«¯å£è¢«å ç”¨æˆ–è€…å¡æ²¡åˆ†é…å¤Ÿï¼Œå°±ä¸æ–­çš„ `ray stop` å’Œ `ray start` ç›´åˆ°æˆåŠŸä¸ºæ­¢ã€‚æ­¤å¤–ï¼Œray æ˜¯éå¸¸å¼ºå¤§çš„èµ„æºè°ƒåº¦å™¨ï¼Œå¦‚æœè¿™é‡Œå¼€çš„æ˜¯ 6 å¼ å¡ï¼Œé‚£ä¹ˆå‰©ä¸‹ 3 å¼ å¡è¿˜å¯ä»¥å†è¢«åˆ†é…ç»™å…¶ä»–ä»»åŠ¡ã€‚

<details>
<summary> ray start çš„è¾“å‡º </summary>

```bash
ray start --head --node-ip-address 127.0.0.1 --num-gpus 3 --port 4567

Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.

Local node IP: 172.31.54.252

--------------------
Ray runtime started.
--------------------

Next steps
  To add another node to this Ray cluster, run
    ray start --address='172.31.54.252:4567'

  To connect to this Ray cluster:
    import ray
    ray.init(_node_ip_address='172.31.59.18')

  To submit a Ray job using the Ray Jobs CLI:
    RAY_ADDRESS='http://127.0.0.1:8265' ray job submit --working-dir . -- python my_script.py

  See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html
  for more information on submitting Ray jobs to the Ray cluster.

  To terminate the Ray runtime, run
    ray stop

  To view the status of the cluster, use
    ray status

  To monitor and debug Ray, view the dashboard at
    127.0.0.1:8265

  If connection to the dashboard fails, check your firewall settings and network configuration.
```

</details>

è¿™é‡Œç»™å‡ºäº† ray çš„ start addressï¼Œä¹Ÿå³  `ray start --address='172.31.59.18:4567'`ï¼Œæ³¨æ„ä¹‹åè¦åœ¨ OpenRLHF çš„æŒ‡ä»¤ä¸­ä½¿ç”¨è¿™ä¸ªåœ°å€ã€‚è€Œåä¹Ÿç»™å‡ºäº† ray dashboard çš„åœ°å€ï¼Œä¹Ÿå³ `127.0.0.1:8265`ï¼Œç™»ä¸Šå»å¯ä»¥æŸ¥çœ‹åˆ°éå¸¸ç²¾ç»†çš„ç›‘æ§ä¿¡æ¯ã€‚

æ¥ç€ï¼Œsubmit ä¸€ä¸ª test jobï¼Œè¿™æ˜¯æˆ‘åœ¨ 3 å¼  H100 ä¸Šè·‘é€šäº†çš„è„šæœ¬ï¼Œå¯ä»¥å‚è€ƒã€‚

<details>
<summary> Test Job </summary>

```bash
# æ ¹æ®éœ€æ±‚ï¼Œè°ƒæ•´ url ray start address, working_dir å’Œ save_path

ray job submit --address="172.31.59.18:4567" \
   --runtime-env-json='{"working_dir": "/opt/dlami/nvme/chenyang/rlhf-ckpt"}' \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path /opt/dlami/nvme/chenyang/rlhf-ckpt/examples/checkpoint/llama3-8b-rlhf \
   --save_steps 100 \
   --micro_train_batch_size 16 \
   --train_batch_size 128 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 128 \
   --max_samples 512 \
   --max_epochs 1 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing
```

</details>

ä»»ä½•ä¸€å¥—æ¡†æ¶éƒ½å¾—åœ¨æ˜“ç”¨æ€§å’Œæ€§èƒ½ä¹‹é—´ trade offï¼Œæˆ‘å¦‚ä¸Šçš„æŒ‡ä»¤å‡ ä¹å¯ä»¥æœ€å¿«é€Ÿåœ°å®Œæˆ OpenRLHF çš„æµç¨‹æµ‹è¯•ã€‚æ³¨æ„è¿™ä¹ˆå‡ ä¸ªå‚æ•°ï¼š

1. `colocate_critic_reward` å’Œ `colocate_actor_ref`ï¼šå°† critic/reward å’Œ actor/ref æ”¾åœ¨åŒä¸€ä¸ªå¡ä¸Šï¼Œæ˜¾è‘—èŠ‚çœäº†æ˜¾å­˜ï¼Œä½†æ˜¯ä¸­é—´æœ‰ä¸€äº› empty cacheï¼Œä¼šæ‹–æ…¢è®­ç»ƒé€Ÿåº¦ã€‚å¦‚æœä¸å¼€å¯ï¼Œå°±ä¼šå„è‡ªå æ®ä¸€å¼ å¡ï¼Œæ˜¾å­˜å ç”¨ç¿»å€ã€‚
2. `adam_offload`ï¼šå°† adam çš„ä¼˜åŒ–å™¨ offload åˆ° CPU ä¸Šï¼Œæ˜¾è‘—èŠ‚çœäº†æ˜¾å­˜ï¼Œä½†æ˜¯ä¼šæ‹–æ…¢è®­ç»ƒé€Ÿåº¦ã€‚ä¸å¼€å¯ä¼šåœ¨ 80G H100 ä¸Š OOMã€‚
3. `max_samples` æ˜¯ä» `prompt_data` é‡Œé¢è¿›è¡Œé‡‡æ ·çš„æœ€å¤§æ ·æœ¬æ•°ï¼Œå…¶å¿…é¡»å¤§äº `rollout_batch_size`ï¼Œå¦åˆ™ä¸å¤Ÿä¸€è½® rolloutï¼Œä¼šæŠ¥é”™ã€‚

æœ€åï¼Œè¡¥å……ä¸‹å¦‚ä½•å°† openrlhf è¿›ç¨‹åœä¸‹ï¼Œå…¶å®éå¸¸æš´åŠ›ï¼š

```bash
pkill -9 -f train_ppo_ray
```

## åˆ†æ OpenRLHF ä¸­ Ray çš„ä½¿ç”¨

è¿™é‡Œä¸»è¦æ˜¯å‚è€ƒäº†è¿™ç¯‡çŸ¥ä¹ï¼š[å›¾è§£ OpenRLHF ä¸­åŸºäº Ray çš„åˆ†å¸ƒå¼è®­ç»ƒæµç¨‹](https://zhuanlan.zhihu.com/p/12871616401)ï¼ŒåŸæ–‡è®²çš„å¾ˆæ¸…æ¥šï¼Œè¿™é‡Œåšä¸€äº›è¿›ä¸€æ­¥é˜è¿°ï¼Œå¯ä»¥ç»“åˆåŸæ–‡ä¸€èµ·é˜…è¯»ï¼Œæ›´åŠ æ¸…æ™°ã€‚

### Ray çš„ä¸€äº›æ ¸å¿ƒæ¦‚å¿µ

åŸæ–‡ä¸­æåˆ°äº†ä¸€äº› Ray çš„æ¦‚å¿µï¼Œä¸è¿‡ä¸ªäººè§‰å¾—ç¨å¾®æ¨¡ç³Šäº†äº›ï¼Œæ‰€ä»¥è¿›ä¸€æ­¥è¡¥å……ã€‚

1. Placement Group

OpenRLHF é‡Œæœ‰ä¸€ä¸ªå˜é‡ `pg`ï¼Œå¤§å¤šæ•°æ—¶å€™æŒ‡çš„éƒ½æ˜¯ Placement Groupï¼Œè€Œä¸æ˜¯ torch é€šè®¯é‡Œçš„ process groupã€‚Placement Group å¯ä»¥ç†è§£ä¸ºä¸€ç»„èµ„æºåˆ†é…æ–¹æ¡ˆï¼Œå…è®¸ç”¨æˆ·ç²¾ç¡®æ§åˆ¶èµ„æºçš„åˆ†é…å’Œä»»åŠ¡çš„è°ƒåº¦ã€‚æ¯”å¦‚è¿™é‡Œï¼š

```python 
import ray

# åˆ›å»ºPlacement Group
pg = ray.util.placement_group(
    bundles=[{"CPU": 2, "GPU": 1}, {"CPU": 4, "GPU": 2}],
    strategy="PACK"
)

# ä½¿ç”¨Placement Groupæ¥æŒ‡å®šä»»åŠ¡çš„æ‰§è¡Œä½ç½®
@ray.remote(placement_group=pg)
def train_model():
    # è®­ç»ƒæ¨¡å‹çš„ä»£ç 
    pass
```

2. Driver

Ray ç¨‹åºçš„æ§åˆ¶èŠ‚ç‚¹ï¼Œé€šå¸¸æ˜¯ç¨‹åºçš„èµ·å§‹ç‚¹ã€‚å®ƒé€šå¸¸åœ¨ä¸€ä¸ªå•ç‹¬çš„èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œè´Ÿè´£å¯åŠ¨ Ray é›†ç¾¤ã€æäº¤ä»»åŠ¡å¹¶è°ƒåº¦æ‰§è¡Œã€‚Driver ç«¯ä¸ä¼šæ‰§è¡Œè®¡ç®—å·¥ä½œï¼Œè€Œæ˜¯é€šè¿‡è¿œç¨‹è°ƒç”¨å°†è®¡ç®—ä»»åŠ¡åˆ†é…å‡ºå»ã€‚

3. Worker

Worker æ˜¯ Ray é›†ç¾¤ä¸­çš„è®¡ç®—èŠ‚ç‚¹ï¼Œè´Ÿè´£æ‰§è¡Œç”± Driver æäº¤çš„ä»»åŠ¡ã€‚æ¯ä¸ª Worker èŠ‚ç‚¹ä¸Šè¿è¡Œç€å¤šä¸ª Worker è¿›ç¨‹ï¼Œè¿™äº›è¿›ç¨‹ä¼šå¤„ç†æ¥è‡ª Driver æˆ–å…¶ä»– Worker çš„ä»»åŠ¡ã€‚

4. Task

Ray Task æ˜¯æœ€åŸºæœ¬çš„è®¡ç®—å•å…ƒï¼Œé€šå¸¸è¡¨ç¤ºä¸€ä¸ªéœ€è¦æ‰§è¡Œçš„å‡½æ•°æˆ–è€…æ“ä½œï¼Œæ˜¯å¹¶è¡Œæ‰§è¡Œçš„æœ€å°å•ä½ã€‚æ¯ä¸ªä»»åŠ¡éƒ½æ˜¯ä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼Œå®ƒä¼šè¢«åˆ†é…åˆ° Ray é›†ç¾¤ä¸­çš„ä¸€ä¸ª Worker æ‰§è¡Œã€‚**ä»»åŠ¡æ˜¯æ— çŠ¶æ€çš„ï¼Œæ‰§è¡Œå®Œä»»åŠ¡åå®ƒä¸ä¼šä¿å­˜ä»»ä½•çŠ¶æ€ï¼Œæ¯æ¬¡æ‰§è¡Œéƒ½æ˜¯ç‹¬ç«‹çš„ã€‚**

5. Actor ä¸ Actor Handle

ä¸ Task ä¸åŒï¼ŒActor æ˜¯ Ray ä¸­æœ‰çŠ¶æ€çš„è®¡ç®—å•å…ƒï¼Œåœ¨å…¶ç”Ÿå‘½å‘¨æœŸå†…ä¿å­˜å†…éƒ¨çŠ¶æ€ã€‚åˆ›å»ºæ—¶ï¼ŒRay ä¸ºå…¶åˆ†é…ç‹¬ç«‹æ‰§è¡Œå®ä¾‹å¹¶è¿”å›å…¶å¼•ç”¨ Actor Handleã€‚é€šè¿‡ Actor Handle è°ƒç”¨ Actor æ–¹æ³•æ—¶ï¼ŒDriver ä¼šé€šè¿‡ Ray è°ƒåº¦ç³»ç»Ÿå°†è¿™æ¬¡è¯·æ±‚å‘é€ç»™åˆé€‚çš„ Worker èŠ‚ç‚¹ã€‚

```python
import ray

# åˆå§‹åŒ– Ray é›†ç¾¤
ray.init()

# å®šä¹‰ä¸€ä¸ªç®€å•çš„ Actor ç±»
@ray.remote
class Counter:
    def __init__(self, value=0):
        self.value = value

    def increment(self):
        self.value += 1
        return self.value

# åˆ›å»ºä¸€ä¸ª Actor å®ä¾‹ï¼Œè¿”å›çš„å°±æ˜¯ä¸€ä¸ª Actor Handle
counter_handle = Counter.remote()

# é€šè¿‡ Actor Handle è°ƒç”¨ increment æ–¹æ³•
result = ray.get(counter_handle.increment.remote())
print(result)  # è¾“å‡º 1

# å†æ¬¡è°ƒç”¨ increment æ–¹æ³•
result = ray.get(counter_handle.increment.remote())
print(result)  # è¾“å‡º 2
```

æ¯”è¾ƒéº»çƒ¦çš„æ˜¯ï¼ŒRay ç³»ç»Ÿä¸­çš„ Actor å’Œ RLHF ä¸­çš„ Actor æ˜¯ä¸¤ä¸ªæ¦‚å¿µï¼Œåæ–‡ä¹Ÿä¼šç‰¹æ®ŠåŒºåˆ†äºŒè€…ã€‚åœ¨ OpenRLHF ä¸­ï¼Œ`PPORayActorGroup` ä»£è¡¨ Ray ç³»ç»Ÿçš„ Actor ç»„ï¼Œè€Œ `ActorModelRayActor` ä»£è¡¨åŸºäº Ray çš„ RLHF ä¸­çš„ Actorã€‚

### colocate çš„èµ„æºåˆ†é…ç­–ç•¥

OpenRLHF å®ç°äº† Actor/Referenceï¼ŒValue/Reward çš„ colocate ç­–ç•¥ï¼Œä¹Ÿå³ Actor å’Œ Reference ä¼šå…±äº«åŒä¸€ç‰‡è®¡ç®—èµ„æºï¼Œç›´è§‚ä¸Šæˆ‘å‡ ä¹çœä¸‹äº†ä¸€åŠçš„æ˜¾å­˜ï¼Œç›´æ¥é€šè¿‡ `--colocate_actor_ref` å°±å¯ä»¥å¼€å¯ã€‚æ¯”è¾ƒæœ‰è¶£çš„æ˜¯ï¼Œå¼€å¯ colocate åï¼Œå®é™…ä¸Šèµ„æºå¹¶ä¸æ˜¯å¯¹åŠåˆ†çš„ï¼Œè€Œæ˜¯ï¼š

```python
actor_model = PPORayActorGroup(
    args.actor_num_nodes,
    args.actor_num_gpus_per_node,
    ActorModelRayActor,
    pg=pg,
    num_gpus_per_actor=0.75 if pg else 1,
)

ref_model = PPORayActorGroup(
    args.ref_num_nodes,
    args.ref_num_gpus_per_node,
    ReferenceModelRayActor,
    pg=pg,
    num_gpus_per_actor=0.25 if pg else 1,
)
```

è¿™é‡Œæ˜¯ä¸ª trickï¼Œå¤§æ„æ˜¯è¯´æŒ‰ç…§ç›®å‰çš„å¯åŠ¨é€»è¾‘ï¼Œå‡è®¾è¦ actor model è¦ data parallelism å æ®ä¸¤å¼ å¡ï¼Œè®¾ç½® `num_gpus_per_actor=0.5`ï¼Œåˆ™ Ray å…ˆåœ¨ç¬¬ä¸€å¼ å¡ä¸Šç”¨ 0.5 æ˜¾å­˜å¯åŠ¨äº†ç¬¬ä¸€ä¸ª actor modelï¼Œæ¥ä¸‹æ¥è¦åˆ†é…ç¬¬äºŒä¸ªå æ® 0.5 æ˜¾å­˜çš„ actor modelï¼ŒRay ä¼šç»§ç»­å°†ç¬¬äºŒä¸ª actor model åˆ†é…åˆ°ç¬¬ä¸€å¼ å¡ä¸Šï¼Œåˆ©ç”¨çœä¸‹çš„ 0.5ï¼Œè€Œä¸æ˜¯ç¬¬äºŒå¼ å¡ã€‚æ‰€ä»¥ colocate çš„æ—¶å€™ï¼Œé‡‡å–äº† `num_gpus_per_actor=0.75, 0.25` çš„ç­–ç•¥ã€‚å®é™…ä¸Šçš„æ˜¾å¡å¹¶ä¸æ˜¯å¯¹åŠåˆ†çš„ï¼Œè€Œä¸”å¯¹äºåªä½¿ç”¨ä¸€å¼ å¡çš„æƒ…å†µï¼Œè¿™ç§ç­–ç•¥ä¸ä¼šæœ‰å½±å“ã€‚

## æ‰©å±• OpenRLHF çš„æ¨ç†å¼•æ“

æ‹å¥½äº†è¿™äº›å‰åºå·¥ä½œï¼Œæ¥ç€æ¥åšæ­£äº‹ã€‚ä¼—æ‰€å‘¨çŸ¥ï¼Œæˆ‘çš„ä¸€å¤§å·¥ä½œæ˜¯åœ¨ OpenRLHF ç³»ç»Ÿä¸­æ”¯æŒ SGLang backendï¼Œæœ‰ä¸¤ä¸ªå…·ä½“çš„éœ€æ±‚ï¼š

1. æ”¯æŒ SGLang çš„ inferenceï¼Œç¡®ä¿ accuracy å’Œ speed éƒ½èƒ½å¯¹æ‹
2. å°†ç°åœ¨çš„ vllm engine æŠ½è±¡ä¸ºä¸€ä¸ª inference Engine Backend ç±»ï¼Œç„¶åè¿™ä¸ª backend æ”¯æŒ huggingfaceï¼ŒSGLang å’Œ vllm

æ ¹æ®æˆ‘ä¸€ç›´ä»¥æ¥çš„å¼€å‘ç»éªŒï¼Œå…ˆåœ¨è¿™é‡Œæ‹ä¸€æ‹ OpenRLHF ä¸­çš„æ‰€æœ‰ vllm ä½¿ç”¨ï¼Œä»¥æ­¤æ¥å®ç°ç»Ÿä¸€çš„ backendã€‚

### `openrlhf/cli/batch_inference.py`

è¿™ä¸ªæ–‡ä»¶å®ç°äº†ä¸‰ä¸ªåŠŸèƒ½ï¼Œç”¨ vllm å’Œ transformers åš generation ä»¥åŠç”¨ transformers æ¨ç†å¾—åˆ° rewardã€‚è¿™ä¸ªåšæ³•ä¸ä¸€å®šä¸¥è°¨ï¼Œå› ä¸ºä¸¥æ ¼æ„ä¹‰ä¸Šï¼Œinference engine åœ¨ RLHF ä¸­ï¼Œç›®å‰åªèƒ½æ‹¿å»åš generationï¼Œç”Ÿæˆçš„ log probsï¼Œlogitsï¼Œembedding å’Œ reward éƒ½æ˜¯ä¸å‡†çš„ï¼š

> æ¨ç†å¼•æ“çš„ kernal fusion å’Œ training engine å·®è·ä¸å°ï¼Œbatch size ä¸ä¸€æ ·æ—¶ï¼Œæ¨ç†è¯·æ±‚ dispatch åˆ°ä¸åŒçš„ kernal ä¸Šï¼Œç„¶å numerical è¯¯å·®é€å±‚ç´¯è®¡ï¼Œåˆ°äº† log probs è¿™å±‚å°±åˆ°äº†ä¸å¯å¿½è§†çš„ç¨‹åº¦äº†ã€‚è¿™ä¸ªé—®é¢˜åœ¨ bert æ—¶ä»£å°±æœ‰äº†ï¼Œtraining engine å’Œ inference engine çš„ç²¾åº¦å·®å¼‚æ— æ³•è§„é¿ï¼Œè€Œä¸”å…¨å¿ƒæ¥æä¸€ä¸¤ä¸ªæœˆå¯èƒ½å†…éƒ½æ²¡æ³•ä¿®å¤ã€‚
> 
> æ‰€ä»¥ç°åœ¨æ¨ç†å¼•æ“åœ¨ RLHF ä¸­æ›´å¤šæ˜¯åŠ é€Ÿ samplingï¼Œreward å’Œ embedding è¿˜å¾—ç”¨è®­ç»ƒè„šæœ¬æ¥ç®—ï¼Œå¯èƒ½å¾—åŠå¹´åèŠ±å¥½å‡ ä¸ªæœˆç ”ç©¶ç ”ç©¶è¿™ä¸ªé—®é¢˜ã€‚

è¿™ä¸‰ä¸ªå‡½æ•°è¿˜æ˜¯éå¸¸ç®€å•ï¼Œç”±äºæˆ‘æè¿°è¿‡ï¼Œè¦åšä¸€ä¸ªç»Ÿä¸€çš„ backendï¼Œæ‰€ä»¥è¿™ä¸ª file å¤§è‡´çš„ä¿®æ”¹æ€è·¯æ˜¯å¼€ä¸€ä¸ªæ–°çš„ class GenerationBackendï¼Œåœ¨ GenerationBackend é‡Œé¢åšä¸€ä¸ª branchï¼Œå®ç° SGLang, vllm å’Œ transformers çš„ inferenceã€‚

å†™åˆ°è¿™é‡Œï¼Œæˆ‘æ‰å‘ç°ä¸€ä¸ªæƒŠäººçš„äº‹æƒ…ï¼ŒOpenRLHF æ²¡æœ‰å•æµ‹ã€‚æˆ‘å…ˆæµ‹æµ‹è¿™ä¸ªç³»ç»Ÿçš„å¯ç”¨æ€§ï¼Œå‚è€ƒè¿™ä¸ª `examples/scripts/train_rejection_sampling_llama.sh`ï¼Œå†™ä¸€ä¸ªå¯¹æ‹å•ä¾§ï¼š

<details>
<summary> å¯¹æ‹å•æµ‹ </summary>

```bash
# For vllm
export VLLM_WORKER_MULTIPROC_METHOD=spawn

mkdir -p ./checkpoint/llama-3-8b-rejection
GENERATE_OUTPUT=./checkpoint/llama-3-8b-rejection/generate.jsonl
RM_OUTPUT=./checkpoint/llama-3-8b-rejection/rm.jsonl
ITER_LOG_PATH=./checkpoint/llama-3-8b-rejection/iter.log
MODEL_OUTPUT_PATH=./checkpoint/llama-3-8b-rejection

TRAINING_ITERS=10
ROLLOUT_BATCH_SIZE=10240

POLICY_MODEL_PATH=OpenRLHF/Llama-3-8b-sft-mixture

iter=0

python batch_inference.py \
   --eval_task generate_vllm \
   --pretrain $POLICY_MODEL_PATH \
   --bf16 \
   --max_new_tokens 2048 \
   --prompt_max_len 2048 \
   --dataset OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --temperature 0.9 \
   --zero_stage 0 \
   --best_of_n 4 \
   --enable_prefix_caching \
   --tp_size 2 \
   --max_num_seqs 64 \
   --iter $iter \
   --rollout_batch_size $ROLLOUT_BATCH_SIZE \
   --output_path $GENERATE_OUTPUT \
   --max_samples 200
```

```bash
# For SGLang

mkdir -p ./checkpoint/llama-3-8b-rejection
GENERATE_OUTPUT=./checkpoint/llama-3-8b-rejection/generate.jsonl
RM_OUTPUT=./checkpoint/llama-3-8b-rejection/rm.jsonl
ITER_LOG_PATH=./checkpoint/llama-3-8b-rejection/iter.log
MODEL_OUTPUT_PATH=./checkpoint/llama-3-8b-rejection

TRAINING_ITERS=10
ROLLOUT_BATCH_SIZE=10240

POLICY_MODEL_PATH=OpenRLHF/Llama-3-8b-sft-mixture

iter=0

python batch_inference.py \
   --eval_task generate_sglang \
   --pretrain $POLICY_MODEL_PATH \
   --bf16 \
   --max_new_tokens 2048 \
   --prompt_max_len 2048 \
   --dataset OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --temperature 0.9 \
   --zero_stage 0 \
   --best_of_n 4 \
   --enable_prefix_caching \
   --tp_size 2 \
   --max_num_seqs 64 \
   --iter $iter \
   --rollout_batch_size $ROLLOUT_BATCH_SIZE \
   --output_path $GENERATE_OUTPUT \
   --max_samples 200
```

</details>


å†™å®Œæˆ‘æ‰å‘ç°ï¼Œsglang vllm è¿˜æœ‰ openrlhf æœ‰ç€ä¸å¯è°ƒå’Œå†²çªï¼Œsglang å’Œ vllm çš„ torch ä¾èµ–ä¸åŒï¼Œè€Œä¸”ç›®å‰æ— æ³•ä¿®å¤ï¼Œæˆ‘å°è¯•äº†è¯¸å¤š vllm ç‰ˆæœ¬éƒ½æ— æ³•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åªèƒ½åœ¨è¿™é‡Œå¼€å§‹ diverge å‡ºä¸¤ä¸ªç¯å¢ƒã€‚ä½¿ç”¨ä¸¤ä¸ªç¯å¢ƒè€Œä¸æ˜¯ä¸¤ä¸ª docker æ˜¯å› ä¸ºæˆ‘è¿˜æ²¡ä¹ æƒ¯ docker çš„æ˜ å°„ï¼Œä¸æƒ³é‡è®¾ç³»ç»Ÿå˜é‡äº†ã€‚

è£…ç¯å¢ƒç°åœ¨æƒ³æ¥å¯ä»¥å¾ˆç®€å•ï¼Œæˆ‘ä¸€å¼€å§‹è£…çš„æ—¶å€™æ˜¯è‡ªå·±æŠ˜è…¾ï¼Œä½†æ˜¯ç°åœ¨å¯ä»¥å‚è€ƒ [SGLang å¼€å‘è€…æ¨¡å¼çš„ç¯å¢ƒé…ç½®æ–‡æ¡£](https://sgl-project.github.io/references/contribution_guide.html#setting-up-building-from-source)ã€‚è‡³äº openrlhf å’Œ vllmï¼ŒæŒ‰ç€æœ€å¼€å§‹æè¿°çš„ï¼Œå…ˆå®‰è£… openrlhfï¼Œå†å®‰è£… rayï¼Œæœ€åå®‰è£… vllmã€‚è¿™ä¹ˆæäº†åŠå¤©ï¼Œå‘ç°æ–°çš„é›†ç¾¤ torch çš„ nvidia link ä¸€ç›´å¤±è´¥ã€‚å‡ å¹´å‰ï¼Œæˆ‘è¿˜åœ¨å•†æ±¤ç©æ³¥å·´çš„æ—¶å€™ï¼Œå°±é‡åˆ°äº†[è¿™ä¸ªé—®é¢˜](https://github.com/pytorch/pytorch/issues/111469)ï¼Œä¸è¿‡ä¸‰å¹´åï¼Œæˆ‘çš„è§£å†³æ€è·¯ä¹Ÿæˆç†Ÿäº†ä¸å°‘ï¼Œè€Œä¸”ç°åœ¨æœ‰ GPT å¯ä»¥é—®äº†ã€‚è¿™é‡Œè¿˜æ˜¯åˆ—ä¸¾ä¸‹è¿™ä¸ª bug çš„è§£å†³è¿‡ç¨‹ï¼š

1. å‘ç° torch çš„é“¾æ¥ä¸€ç›´æœ‰é—®é¢˜ï¼Œæˆ‘æŒ‰ç…§[è¿™ä¸ª issue](https://github.com/pytorch/pytorch/issues/111469) ç­‰ä¸€ç³»åˆ—æ–¹æ³•æ”¹äº† `LD_LIBRARY_PATH`ï¼Œè¯•è¿‡ docker å’Œ conda ç­‰ç­‰å„ç§ç¯å¢ƒï¼Œè¿˜æ˜¯ torch 2.5.1 çš„é“¾æ¥æœ‰é—®é¢˜ï¼š

```bash
ImportError: /usr/local/lib/python3.10/dist-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
```

2. æˆ‘å‘ç°ï¼Œray submit çš„ job æœ‰è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯ ipython é‡Œé¢æ²¡é—®é¢˜ã€‚è¿›ä¸€æ­¥ç¼©å°èŒƒå›´ï¼Œæˆ‘å‘ç° `python -c` éƒ½æ²¡é—®é¢˜ï¼Œé‚£ä¹ˆé—®é¢˜åœ¨å“ªå„¿å‘¢ï¼Ÿ

3. é—®äº† claudeï¼Œæ˜¯ ray ç¯å¢ƒçš„é—®é¢˜ï¼š

<details>
<summary> claude çš„å›ç­” </summary>

> ä¸æ˜¯ï¼Œå‡­ä»€ä¹ˆä»–å¦ˆçš„ python -c å¯ä»¥ importï¼Œä½†æ˜¯ ray submit çš„å°±ä¸è¡Œï¼Ÿ

å•Šï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„ç¯å¢ƒå˜é‡ç»§æ‰¿é—®é¢˜ã€‚

å½“ä½ åœ¨æœ¬åœ°ç»ˆç«¯æ‰§è¡Œ `python -c` æ—¶ï¼Œå®ƒç»§æ‰¿äº†ä½ åœ¨ `.zshrc` ä¸­è®¾ç½®çš„æ‰€æœ‰ç¯å¢ƒå˜é‡ï¼ˆåŒ…æ‹¬ `LD_LIBRARY_PATH`ï¼‰ã€‚ä½†æ˜¯å½“é€šè¿‡ ray submit æäº¤ä»»åŠ¡æ—¶ï¼Œè¿™äº›ç¯å¢ƒå˜é‡å¯èƒ½æ²¡æœ‰è¢«æ­£ç¡®ä¼ é€’åˆ° ray worker è¿›ç¨‹ä¸­ã€‚

å»ºè®®å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š

1. åœ¨ ray ä»»åŠ¡ä¸­æ˜¾å¼è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```python
import os
os.environ["LD_LIBRARY_PATH"] = "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages/nvidia/cusparse/lib"
```

2. æˆ–è€…åœ¨ ray.init() æ—¶é€šè¿‡ runtime_env ä¼ é€’ï¼š
```python
ray.init(runtime_env={
    "env_vars": {
        "LD_LIBRARY_PATH": "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages/nvidia/cusparse/lib"
    }
})
```

3. å¦‚æœä½¿ç”¨ ray submitï¼Œå¯ä»¥åœ¨æäº¤è„šæœ¬ä¸­æ·»åŠ ï¼š
```bash
export RAY_RUNTIME_ENV='{"env_vars": {"LD_LIBRARY_PATH": "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages/nvidia/cusparse/lib"}}'
ray submit script.py
```

è¿™æ ·åº”è¯¥èƒ½ç¡®ä¿ç¯å¢ƒå˜é‡è¢«æ­£ç¡®ä¼ é€’åˆ° ray worker ä¸­ã€‚


</details>

é—®é¢˜è§£å†³ï¼Œæˆ‘åœ¨ submit job çš„æ—¶å€™ï¼Œå¾—å†™æˆè¿™æ ·ï¼š

```bash
export RAY_RUNTIME_ENV='{"env_vars": {"LD_LIBRARY_PATH": "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages/nvidia/cusparse/lib"}}'
ray submit script.py
```


<!-- å¾ˆçƒ¦ï¼Œä½ çœ‹æˆ‘å’Œ claude å¯¹è¯éƒ½å¿«ç›´æ¥éª‚äººäº†ã€‚ä»Šå¤©çœ‹ä¸Šå»åšäº†å¾ˆå¤šäº‹æƒ…ï¼Œå®é™…ä¸Šæ€»è§‰å¾—åœ¨åŸåœ°è¸æ­¥ï¼š

1. å‘ç°æœ€æ–°çš„ vllm, sglang å’Œ openrlhf çš„ä¾èµ–å†²çªç›®å‰æ²¡æ³•è§£å†³ï¼Œä¸å•å•æ˜¯ outlines çš„é—®é¢˜ï¼Œæ›´æ·±å±‚æ˜¯ torch çš„é—®é¢˜ã€‚æˆ‘åˆå°è¯•ç”¨ vllm 0.6.3.post1 å’Œ vllm 0.6.4.post1ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½å…¼å®¹ï¼Œç»“æœåªæœ‰ vllm 0.6.5 çš„ `update_weights_from_distritbued` åœ¨å½“æ—¶çš„ç¯å¢ƒé‡ŒæˆåŠŸäº†ï¼Œå…¶ä»–ç‰ˆæœ¬éƒ½ä¸è¡Œï¼Œåˆç”¨äº†ä¸€ä¸ªå°æ—¶ã€‚ 
2. æ²¡æ³•äº†ï¼Œå°è¯• diverge ç¯å¢ƒï¼Œå´å‘ç°ç¬¬ä¸€ä¸ªé›†ç¾¤åœ¨å†™å…¥æ—¶å´©äº†ï¼Œå¤©çŸ¥é“æ˜¯ä¸æ˜¯æˆ‘å¹²çš„ï¼Œå¯æˆ‘ä»æ¥ä¸å†™å…¥åˆ° `/home` å•Šã€‚
3. åˆ‡æ¢é›†ç¾¤ï¼Œä¿®æ”¹è‹¥å¹²å¤šé…ç½®ï¼Œç»ˆäºæŠŠå¦ä¸€å° H100 è®¾ç½®å¥½äº†ã€‚æ¥ç€å‘ç°äº†å¤©ä½¿çš„ torch link errorã€‚å°è¯•å„ç§åŠæ³• de äº† 2hï¼Œå…ˆç”¨ conda å¼€æ–°ç¯å¢ƒï¼Œå†ç”¨ docker è¯•å›¾ç»•è¿‡ torch linkï¼Œå‘ç°æ— æœï¼Œéå¸¸ç»æœ›ã€‚
4. åœ¨ç¾¤é‡Œç»™å¤§å®¶æ±‡æŠ¥é—®é¢˜ï¼Œé¡ºå¸¦è¯•äº†è¯• `python -c`ï¼Œçœ‹çœ‹ä¼šä¸ä¼š errorã€‚å‘ç°æ²¡æœ‰ï¼Œç»ˆäºé—®äº† claudeï¼Œå‘ç°äº† ray çš„ç¯å¢ƒå˜é‡é—®é¢˜ã€‚è¦æ˜¯æ²¡æœ‰ç°ä»£ LLMï¼Œè¿™ bug å›åˆ°ä¸¤å¹´å‰çœŸçš„ä¼šè®©æˆ‘è‡ªé—­ï¼Œåˆæƒ³èµ·äº†ç–«æƒ…æœŸé—´æˆ‘åœ¨ç´«äºŒ 308 å¯¹ç€å•†æ±¤çš„é›†ç¾¤é…ç½® deepspeed çš„ç—›è‹¦ï¼Œå…œå…œè½¬è½¬åˆå›åˆ°äº†è¿™ç§å¢ƒé‡ã€‚
5. å…¶å®è¿˜é‡åˆ°ä¸€äº›é—®é¢˜ï¼Œæ€»ä½“ä¸Šæ˜¯æˆ‘æ²¡æœ‰è€å¿ƒï¼Œæ¯”å¦‚è§‚å¯Ÿåˆ° openrlhf çš„è¿›ç¨‹å¡åœ¨äº† DeepSpeedEngine compile ä¸Šï¼Œæˆ‘å°±ä¼šåœæ‰é‡å¼€ã€‚äº‹åå‘ç°ï¼Œå…¶å®ç¬¬ä¸€æ¬¡å°±æ˜¯è¦ç­‰å¾ˆä¹…ã€‚éƒ­ç£Šä¸€ä¼šå„¿ï¼Œæˆ‘çš„ training åˆå¡ä½äº†ï¼Œè¿™æ¬¡å¡åœ¨ vllm broadcast weights ä¸Šã€‚è¯´å®è¯ï¼Œæˆ‘æœ‰ç‚¹å´©æºƒï¼Œå› ä¸ºæˆ‘çŸ¥é“è¿™ä¸ª broadcast ä¸ä¼šèŠ±è´¹é‚£ä¹ˆä¹…ï¼Œä¹‹å‰è°ƒæˆ 0.6.5 å¯ä»¥ï¼Œç°åœ¨ä¸è¡Œäº†ã€‚æˆ‘åˆå†é‡è£…ä¸€æ¬¡ç¯å¢ƒï¼Œå› ä¸ºä¹‹å‰ä¸€æ¨¡ä¸€æ ·çš„é—®é¢˜éƒ½æ˜¯è¿™æ ·è§£å†³çš„ã€‚
6. è¿˜æ˜¯ä¸å¯¹ï¼Œé—®äº† OpenRLHF ä½œè€…ï¼Œè¯´æ˜¯ vllm æ›´æ–°åˆæå´©äº†ï¼Œweights update çš„ bug åˆå‡ºç°äº†ã€‚è¿™æ‰å‘ç°ï¼Œå¤§å®¶éƒ½ç„¦å¤´çƒ‚é¢çš„ï¼Œè¿™å°±æ˜¯ mlsys çš„å¸¸æ€å§...ä»–å»ºè®®æˆ‘ç”¨ openrlhf çš„ç¨³å®šç‰ˆæœ¬ï¼Œåˆ«ç”¨ mainã€‚æˆ‘æ¢åˆ° 0.5.4ï¼Œè¿˜æ˜¯å´©äº†ã€‚

ä¸è¯´äº†ï¼Œç»ˆäºæåˆ°äº†ä¸€ä¸ªç¨³å®šçš„å¼€å‘ç¯å¢ƒï¼Œæ˜å¤©å» review æœ‹å‹ç»™æˆ‘çš„ PRï¼Œç„¶ååœ¨ä¹‹å‰ç»™ OpenRLHF çš„ PR ä¸Šè¯´æ˜ç›®å‰çš„æƒ…å†µã€‚**ä»Šå¤©æŠŠä¹‹å‰åˆ äº†çš„ lolm ä¸‹è½½äº†å›æ¥ï¼Œå¦ˆçš„ï¼Œlolm å¯åŠ¨ã€‚è¿™ lolm é‡Œé¢æœ‰ llmï¼ŒçœŸæ˜¯å¤©æ„ã€‚** -->

æœ€åï¼Œè¿™äº›è§£å†³äº†ä¹‹åï¼Œè¿˜è·‘ç€è·‘ç€é‡åˆ°äº†æœåŠ¡å™¨çˆ†ç‚¸ï¼Œè¿ ssh éƒ½è¿ä¸ä¸Šå»ã€‚ç»“æœæœ€åå‘ç°æ˜¯ ray çš„ logging ä¼šé»˜è®¤åˆ° `tmp/ray` ä¸‹é¢ï¼Œç„¶åè¿™ä¸ª log è¿˜è´¼å¤§ï¼ŒæŠŠ `tmp` ç»™æ’‘çˆ†äº†ã€‚ssh ä¹Ÿæ˜¯è¦å¾€ `tmp` é‡Œé¢å†™ä¸œè¥¿çš„ï¼Œæ‰€ä»¥ç›´æ¥å¹²å®äº†ä¸€å° H100ï¼Œæ„Ÿè°¢ NV åœ¨åœ£è¯èŠ‚åŠ ç­ç»™æ¢äº†å°æ–°çš„ã€‚æ€»ä¹‹ï¼Œè¿™ä¸¤ä¸ª bug åˆåœ¨ä¸€èµ·çš„è§£å†³æ–¹æ¡ˆå¦‚ä¸‹ï¼š

```bash
# ray å¯åŠ¨çš„æ—¶å€™æŒ‡å®š temp dir
ray start --head --node-ip-address 127.0.0.1 --num-gpus 6 --port 1234 --temp-dir="/root/.cache/ray"

# æäº¤ job çš„æ—¶å€™æŒ‡å®š env var
export RAY_RUNTIME_ENV='{"env_vars": {"LD_LIBRARY_PATH": "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages/nvidia/cusparse/lib"}}'

ray submit script.py
```

### `openrlhf/cli/train_ppo_ray.py`

PPO å¯èƒ½æ˜¯æˆ‘è§‰å¾— openrlhf æœ€é‡è¦çš„ training è„šæœ¬ï¼Œä¹Ÿæ˜¯æˆ‘ä¹‹å‰ä¸»è¦æµ‹è¯•çš„åœ°æ–¹ã€‚æˆ‘å…ˆè®°å½•ä¸‹æˆ‘çš„ç¯å¢ƒï¼Œé¿å…å°†æ¥å‘ç”Ÿç¯å¢ƒå†²çªï¼š

- openrlhf[vllm]: main ä¸Šçš„ openrlhf, vllm 0.6.5, torch 2.5.1, outlines 0.1.11, ray 2.12.0
- openrlhf[sglang]: main ä¸Šçš„ openrlhf, sglang 0.4.1, torch 2.5.1+cu121, vllm 0.6.4.post1, outlines 0.0.46, ray 2.12.0

è¯´æ¥ä»¤äººå”å˜˜ï¼Œæˆ‘åœ¨ä¸¤æ¬¡åŠ¨ç¬”å†™è¿™éƒ¨åˆ†æ–‡æ¡£ä¹‹é—´ï¼Œå·²ç»è¿‡äº†æ¥è¿‘ä¸¤å‘¨æ—¶é—´äº†ã€‚ä»å¥½å¤„æƒ³ï¼Œæˆ‘æˆåŠŸæ¥å…¥äº† sglang åˆ° openrlhfï¼Œä½†æ˜¯åæ¶ˆæ¯æ˜¯ï¼ŒäºŒè€…è¿œè¿œæ²¡æœ‰åˆ°è¾¾ä¸€ä¸ªç¨³å®šæ›¿æ¢çš„åœ°æ­¥ï¼Œåœ¨æˆ‘ä»¬çš„ H100 ä¸Šï¼Œç»å¸¸ä¼šåœ¨ç¨³å®šè®­ç»ƒä¸€ä¸¤å¤©åï¼Œåœ¨ deepspeed çš„æŸä¸€æ­¥ä¸Š nccl hang ä½ï¼Œé™·å…¥ deadlockã€‚è¿™å°±éå¸¸åäººç±»äº†ï¼Œå› ä¸ºå‰å‡ ä¸ª epoch éƒ½ä¸ä¼šå†é‚£ä¸ª step hang ä½ï¼Œå°±æ¯”å¦‚è¯´ backward è¿›è¡Œåˆ° 91% ä¹‹åå°±å¡æ­»äº†ï¼Œæˆ‘ç™¾æ€ä¸å¾—å…¶è§£ã€‚åœ¨å¦‚ä¸‹çš„æ–‡æ¡£ä¸­ï¼Œæˆ‘å…ˆè®°å½•ä¸‹å¦‚ä½•åœ¨ PPO ä¸­çš„ vllm engine ä¹‹å¤–é¢å¤–æ”¯æŒ sglang engineã€‚ç„¶åï¼Œé€æ­¥ç»™å‡ºæ¨å¯¼ï¼Œåˆ†ææˆ‘è§‰å¾—å¯èƒ½ hang çš„åŸå› ã€‚å½“ç„¶ï¼Œæœ€è¿‘æˆ‘ä»¬ä¹Ÿæ‰¾äº† deepspeed çš„æ ¸å¿ƒå¼€å‘è€…å’Œæˆ‘ä»¬ä¸€èµ· debug nccl hangã€‚

å›åˆ° PPO ä¸Šï¼Œè¿™é‡Œç…§ç€æˆ‘ PR çš„ file changes æ¥è®¨è®ºã€‚è‡³äº `train_ppo_ray.py` è¿™ä¸ª file æœ¬èº«ï¼Œå…¶å®è¿™ä¸ªæ”¹åŠ¨æ˜¯å¾ˆå°çš„ï¼Œè¿™ä¸ªæ–‡ä»¶å°±æ˜¯æŠŠæ‰€æœ‰å«åš `vllm_engines` çš„å˜é‡æ”¹ä¸º `inference_engines` çš„é€šç”¨åå­—ï¼Œç„¶ååŠ ä¸Š `--backend` å‚æ•°ã€‚

### `openrlhf/trainer/ppo_utils/experience_maker.py`

æœ¬è´¨ä¸Š RLHF é‡Œé¢ï¼Œinference engine å°±æ˜¯ç”¨äº make experience çš„ï¼Œæ‰€ä»¥è¿™ä¸ªæ”¹åŠ¨è›®å¤§çš„ã€‚

- **`llm.generate`**

ã€TODOã€‘

é¦–å…ˆï¼ŒåŸå…ˆçš„ï¼š

```python
llm.generate.remote(sampling_params=sampling_params, prompt_token_ids=prompt_token_ids)
```

æˆ‘æ”¹ä¸ºäº†ï¼š

```python
llm.generate.remote(
    sampling_params=sampling_params, prompt_token_ids=prompt_token_ids, all_prompts=all_prompts
)
```

è¿™ä¸ªå…¶å®æ˜¯ vllm å’Œ sglang çš„å·®å¼‚ï¼Œåœ¨ openrlhf çš„æºä»£ç é‡Œé¢ï¼Œç»™ vllm engine ç›´æ¥ä¼ å…¥äº† `prompt_token_ids`ï¼Œè¿™ä¸ªå¤§æ¦‚æ˜¯ `input_ids`ï¼Œè€Œæˆ‘å…ˆå®ç°äº†å¯¹ sglang ä¼ å…¥ prompts åš generateã€‚æ­£å¦‚æˆ‘å·²ç»è¯´è¿‡çš„ï¼Œvllm training engine å’Œ sglang training engine éƒ½ä¼šå‡ºç°æ•ˆç‡ä¸ç¨³å®šè€Œå¡æ­»çš„æƒ…å†µï¼Œæˆ‘ä¸ç›¸ä¿¡è¿™æ˜¯æˆ‘å¼•å…¥çš„é—®é¢˜ã€‚ä½†æˆ‘ç¡®å®æ€€ç–‘æœ‰äº›ç»†å¾®çš„å·®å¼‚å¸¦æ¥äº†ä¸å°çš„å½±å“ï¼Œè­¬å¦‚ vllm engine ä¼ å…¥ token ids å’Œ sglang engine ä¼ å…¥ prompts ä¼šä¸ä¼šæœ‰å·®åˆ«ï¼ŒåŠ äº†äº›å¥‡æ€ªçš„ tokensï¼Ÿæ­¤å¤–ï¼Œsglang engine é‡Œé¢è¿˜è¦å† tokenize ä¸€æ¬¡ï¼Œå¸¦æ¥äº†ä¸å¯å¿½ç•¥çš„ overheadã€‚æ‰€ä»¥è¿™é‡Œæˆ‘æœ‰ä¸‰ä¸ª TODOï¼Œéƒ½å»å®ç°ä¸‹ï¼š

1. ç›´æ¥ä¼ å…¥ token ids ç»™ sglangï¼Œä¸è¦å†å¯¹ prompts tokenize ä¸€æ¬¡äº†ã€‚
2. æ‰“å°å‡º tokens çš„å¼€å§‹å’Œç»“å°¾ï¼Œç”¨äºæ£€æŸ¥ vllm å’Œ sglang å¤„ç†ç‰¹æ®Š token æ˜¯å¦æœ‰åŒºåˆ«ã€‚
3. æ‰“å°å‡ºä¼ å…¥ç»™ experience making çš„ tokens çŸ©é˜µå¤§å°ï¼Œéš¾é“äºŒè€…çš„çŸ©é˜µå¤§å°å·®å¼‚ï¼ˆè­¬å¦‚æœ€é•¿çš„ string ç‰¹åˆ«é•¿å¯¼è‡´ padding åå·®å¼‚ç‰¹åˆ«å¤§ï¼‰ä¼šæœ‰æ˜¾è‘—å½±å“ä¹ˆï¼Ÿ

- **token collection**

è¿™ä¸ªæ”¹åŠ¨å°±æ²¡ä»€ä¹ˆæ„æ€äº†ï¼Œæˆ‘æ‰‹åŠ¨ collect äº†æ‰€æœ‰çš„ `input_ids` å’Œ `output_ids`ï¼Œé¿å…äº†ä¸‹é¢å‡ ä¸ªä¸å¤Ÿä¼˜é›…çš„ for å¾ªç¯ã€‚

<details>
<summary> åŸºäºåˆ—è¡¨æ¨ç†çš„æ”¹åŠ¨ </summary>

åŸæœ¬ï¼š

```python

max_input_len, max_output_len = 0, 0
for output in outputs:
    max_input_len = max(max_input_len, len(output.prompt_token_ids))
    max_output_len = max(max_output_len, len(output.outputs[0].token_ids))
```

æˆ‘çš„æ”¹åŠ¨ï¼š

```python
input_token_id_list = None
output_token_id_list = None
if backend == "vllm":
    input_token_id_list = [list(output.prompt_token_ids) for output in outputs]
    output_token_id_list = [list(output.outputs[0].token_ids) for output in outputs]
else:
    input_token_id_list = [list(output["input_ids"]) for output in outputs]
    output_token_id_list = [list(output["output_ids"]) for output in outputs]

max_input_len = max(len(input_id) for input_id in input_token_id_list)
max_output_len = max(len(output_id) for output_id in output_token_id_list)
```
</details>

ä¸å¾—ä¸è¯´åŸæœ¬é‚£ä¸ªéå†åˆ—è¡¨å–æœ€å¤§å€¼çš„æ“ä½œç¡®å®ä¸å¤ªç§‘å­¦ï¼Œç”¨åˆ—è¡¨æ¨å¯¼æ˜¯å¾ˆåŸºæœ¬çš„ pythonic æ“ä½œäº†ã€‚æˆ‘ç¡®ä¿¡è¿™ç§æ”¹åŠ¨æ˜¯å®Œå…¨ç­‰ä»·çš„ï¼Œæ¯•ç«Ÿè¦æ˜¯è¿™ç§ç­‰ä»·æ›¿æ¢éƒ½åšä¸å¥½ï¼Œæœ¬ç§‘æŠ„çš„å››å¹´ä»£ç ï¼Œæ—©è¯¥æ¯•ä¸äº†ä¸šäº†...ç„¶è€Œï¼Œä»¤æˆ‘è´¹è§£çš„æ˜¯ï¼Œè™½ç„¶å¦‚æ­¤æ”¹åŠ¨åœ¨æˆ‘çœ‹æ¥ç­‰ä»·ï¼Œä¸ºä»€ä¹ˆä¼šå‡ºç°  nccl hang å‘¢ï¼Ÿæˆ‘æ²¡æœ‰æµ‹è¯•è¿‡ mainï¼Œæ˜¯å¦æ˜¯ main æœ¬èº«å°±æœ‰é—®é¢˜ã€‚äºæ˜¯ï¼Œæˆ‘åˆæœ‰äº†ä¸€ä¸ª TODOï¼š

- æµ‹è¯• main ä¸Šæ˜¯å¦ä¹Ÿä¼šå¡é¡¿ï¼Ÿ

### `openrlhf/trainer/ray/ppo_actor.py`

è¿™ä¸ªæ–‡ä»¶é™¤å¼€å‘½åä¹‹å¤–ï¼Œæˆ‘å‡ ä¹æ²¡æœ‰ä»€ä¹ˆæ”¹åŠ¨ã€‚æœ‰ä¸ªå€¼å¾—æ³¨æ„çš„åœ°æ–¹æ˜¯ï¼Œæˆ‘æŠŠ `init_process_group` çš„ backend ä» `gloo` ç»Ÿä¸€æ”¹ä¸ºäº† `nccl`ï¼Œå› ä¸ºæŸä¸€æ¬¡å‡ºç°äº† process group åˆ›ç«‹é”™è¯¯ï¼Œä½†æ˜¯ `nccl` åš backend æ˜¯ç¨³å®šçš„ã€‚éš¾é“è¿™æ˜¯é€ æˆä¸ç¨³çš„åŸå› ï¼š

- æµ‹è¯•æ˜¯å¦æ˜¯ backend çš„é—®é¢˜ï¼Ÿ

### `openrlhf/trainer/ray/vllm_engine.py`

è¿™æ˜¯æœ€å¤§çš„æ”¹åŠ¨ï¼Œé“ç†å¾ˆç®€å•ï¼Œç²—ç³™çš„æ”¹æ³•å°±æ˜¯å°±æ˜¯åœ¨è¿™ä¸ªæ–‡ä»¶ä¸‹é¢åŠ å…¥ branchï¼Œæ ¹æ® backend é€‰æ‹©ä¸åŒçš„ engineã€‚æˆ‘è¿˜æ²¡æœ‰æ¥å¾—åŠä¿®æ”¹æ–‡ä»¶åï¼ŒæŒ‰ç†è¯´è¦æ”¹æˆ `inference_engine.py`ã€‚ä¸è¿‡è¿™äº›é—®é¢˜ä¹‹åè§£å†³éƒ½å¥½...

vllm çš„åœ°æ–¹ä¸ç”¨æ”¹ï¼Œåªæ˜¯ç§»åŠ¨åˆ° if ä¸‹é¢å°±è¡Œï¼Œä½†æ˜¯ sglang çš„åœ°æ–¹å¾—æ”¹åŠ¨ä¸å°‘ï¼Œä¸»è¦æ˜¯ `LLMRayActor` çš„ `__init__` ä¼ å…¥çš„æ˜¯ `*args, **kwargs`ï¼Œç›´æ¥å¯¹ç€ vllm çš„ server args åœ¨å¯åŠ¨ï¼Œå¦‚æœæˆ‘ç›´æ¥ä¼ ç»™ `sglang.Engine`ï¼Œä¼šå› ä¸ºä½ç½®å‚æ•°åŒ¹é…ä¸ä¸Šè€ŒæŠ¥é”™ã€‚æ‰€ä»¥ï¼Œæˆ‘å¾—æ‰¾å¯» sglang å’Œ vllm çš„å¯¹åº”å‚æ•°ï¼Œä½†æ˜¯è¿™ä¸ªäº‹æƒ…åœ¨ [batch_inference.py](#openrlhfclibatch_inferencepy) é‡Œé¢å·²ç»åšè¿‡äº†ï¼Œæˆ‘æ€€ç–‘å¯èƒ½ä¹Ÿæœ‰é”™ã€‚è¿™é‡Œè®°å½•ä¸‹æˆ‘çš„åšæ³•ï¼š

<details>
<summary> ä» vllm åˆ° sglang çš„ server args æ˜ å°„ </summary>

è¿™æ˜¯ vllm çš„ server parametersï¼š

```python
#   Pretrain æ˜¯ model pathï¼Œè¿™åå­—æ€ªæŠ½è±¡çš„
pretrain,
noset_visible_devices=noset_visible_devices,
trust_remote_code=True,
tensor_parallel_size=tensor_parallel_size,
dtype="bfloat16",
seed=seed + i,
enable_prefix_caching=enable_prefix_caching,
enforce_eager=enforce_eager,
max_model_len=max_model_len,
backend=backend,
```        

è¿™æ˜¯æˆ‘åœ¨ sglang é‡Œçš„æ˜ å°„ï¼š

```python
#! TODO chenyang check engine params
sglang_params = {
    "model_path": args[0],  # pretrain path
    "trust_remote_code": kwargs.get("trust_remote_code", True),
    "dtype": kwargs.get("dtype", "auto"),
    "tp_size": kwargs.get("tensor_parallel_size", 1),
    "device": "cuda",
    "disable_radix_cache": not kwargs.get("enable_prefix_caching", False),
    "random_seed": kwargs.get("seed", 42),
    "disable_cuda_graph": not kwargs.get("enforce_eager", False),
    "disable_cuda_graph_padding": not kwargs.get("enable_prefix_caching", False),
    "context_length": kwargs.get("max_model_len", None),
    "log_level": "info",
    "return_token_ids": True,
}
self.llm = sglang.Engine(**sglang_params)
```

</details>

è€å®è¯´æˆ‘è¿˜æŒºæœ‰ä¿¡å¿ƒçš„ï¼Œä½†æ˜¯ä¹Ÿä¸å¾—ä¸æŸ¥å•Šã€‚æ³¨æ„ `return_token_ids` æ˜¯ä¸“é—¨ä¸º openrlhf å†™çš„æ–° featureï¼Œè¿™é‡Œå¾—æ„Ÿè°¢ [Shuai Shi](https://github.com/shuaills) çš„è¿™ä¸ª [PR](https://github.com/sgl-project/sglang/pull/2636)ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ç¬¬ä¸€æ¬¡ mentor äººå†™çš„ SGLang PRï¼Œå¾ˆæœ‰æˆå°±æ„Ÿï¼Œä½†æ˜¯æˆ‘è‡ªå·±å…¶å® PR éƒ½æ²¡å‡ ä¸ª ğŸ¤£ğŸ¤£ğŸ¤£

è¯´å›åˆ°è¿™äº›å‚æ•°ï¼Œè¿˜æœ‰ `log_level = "info"` æ˜¯æ€œæ‚¯è®©æˆ‘åŠ çš„ï¼Œçœ‹çœ‹ inference engine æ˜¯ä¸æ˜¯ fully ultized äº†ã€‚ç›®å‰çœ‹äº†çœ‹ `token usage = 0.61`ï¼Œæ„Ÿè§‰æ˜¯è¿˜å¯ä»¥çš„ï¼Œä½†æ˜¯æ€œæ‚¯è¯´å¯ä»¥çœ‹çœ‹ `cache hit rate`ï¼Œè¿™ä¸ªä¹‹åçœ‹çœ‹ã€‚è¿™é‡Œå†æ¥ä¸‰ä¸ª TODO:

1. æ£€æŸ¥ vllm åˆ° sglang çš„å‚æ•°æ˜ å°„æ˜¯å¦æ­£ç¡®ï¼Ÿ
2. åŒæ ·çš„ï¼Œæ£€æµ‹ sampling params æ˜¯å¦æ­£ç¡®ï¼Ÿ
3. æŸ¥çœ‹ cache hit rateï¼Œæ€§èƒ½ä¸Šåº”è¯¥è¿˜æœ‰æå‡ç©ºé—´ã€‚

éƒ½æåˆ° 2 äº†ï¼Œå½“ç„¶æˆ‘ä¹Ÿå¾—å¯¹ sampling params åšæ˜ å°„ï¼Œåœ¨æˆ‘çš„æ˜ åƒä¸­ï¼Œsglang åº”è¯¥æ˜¯å®Œå…¨è´´ç€ openai api å†™çš„ sampling paramsï¼Œä½†æ˜¯è¿˜æ˜¯å¾—æ£€æŸ¥ parameter æ˜ å°„ã€‚

<details>
<summary> ä» vllm åˆ° sglang çš„ sampling params æ˜ å°„ </summary>

```python
if self.backend == "vllm":
    outputs = self.llm.generate(
        sampling_params=kwargs["sampling_params"], prompt_token_ids=kwargs["prompt_token_ids"]
    )
elif self.backend == "sglang":
    # Note that sglang sampling params are different from vllm
    sampling_params = kwargs["sampling_params"]
    all_prompts = kwargs["all_prompts"]

    # min_tokens, include_stop_str_in_output is not used in sglang

    sampling_params = dict(
        max_new_tokens=sampling_params.max_tokens,
        top_p=sampling_params.top_p,
        top_k=sampling_params.top_k,
        temperature=sampling_params.temperature,
        repetition_penalty=sampling_params.repetition_penalty,
        skip_special_tokens=sampling_params.skip_special_tokens,
    )
    outputs = self.llm.generate(all_prompts, sampling_params)
```

å½“ç„¶ï¼Œå‰ç«¯ä¼ è¿›æ¥çš„ sampling params å¦‚ä¸‹ï¼š

```python
sampling_params = SamplingParams(
    temperature=kwargs.get("temperature", 1.0),
    top_p=kwargs.get("top_p", 1.0),
    top_k=kwargs.get("top_k", -1),
    max_tokens=kwargs.get("max_new_tokens", 1024),
    min_tokens=kwargs.get("min_new_tokens", 1),
    skip_special_tokens=kwargs.get("skip_special_tokens", False),
    include_stop_str_in_output=True,
)
```
</details>

ä¹‹åï¼Œæ˜¯ `init_process_group` å’Œ `update_weight`ï¼Œæˆ‘çœŸçš„å¤ªç†Ÿæ‚‰ä¸è¿‡äº†ã€‚å› ä¸ºè¿™ä¿©æ¥å£æ˜¯æˆ‘å†™çš„ï¼Œæˆ‘çœ‹ openrlhf è²Œä¼¼ç›®å‰ç”¨çš„è¿˜æ˜¯ä»–ä»¬è‡ªå·±å†™çš„ Wrapperï¼Œä¸æ˜¯vllm çš„å®˜æ–¹ä»£ç ï¼Ÿæ— æ‰€è°“ï¼Œè¿™é‡Œæˆ‘å¾ˆç†Ÿæ‚‰çš„åˆ‡æ¢åˆ° sglang çš„ä»£ç ï¼š

<details>
<summary> å‚æ•°æ›´æ–°çš„ç›¸å…³ä»£ç  </summary>

`init_process_group`ï¼š

```python
if self.backend == "vllm":
    if self.use_gpu_executor:
        return self.llm.llm_engine.model_executor.driver_worker.init_process_group(
            master_address, master_port, rank_offset, world_size, group_name, backend
        )
    else:
        return self.llm.llm_engine.model_executor._run_workers(
            "init_process_group", master_address, master_port, rank_offset, world_size, group_name, backend
        )
elif self.backend == "sglang":
    return self.llm.init_weights_update_group(
        master_address, master_port, rank_offset, world_size, group_name, backend="nccl"
    )
```

`update_weight`ï¼š

```python
if self.backend == "vllm":
    self.stop_remote_worker_execution_loop()

    if self.use_gpu_executor:
        return self.llm.llm_engine.model_executor.driver_worker.update_weight(name, dtype, shape, empty_cache)
    else:
        return self.llm.llm_engine.model_executor._run_workers(
            "update_weight", name, dtype, shape, empty_cache
        )
elif self.backend == "sglang":
    return self.llm.update_weights_from_distributed(name, dtype, shape)
```

</details>

è¿™é‡Œå…¶å®æˆ‘ä¹ŸçŠ¯è¿‡è¿·ç³Šï¼Œå› ä¸ºä¸€å¼€å§‹ sglang çš„ training pipeline ä¼š OOMï¼Œæˆ‘å¯¹æ¯”äº†ä¸‹ openrlhf ç»™ vllm å†™çš„ Wrapperï¼Œçœ‹åˆ°ä»–ä»¬æ›´æ–°å®Œäº†å‚æ•°ä¼š `del weights`ï¼Œä½†æˆ‘åœ¨ sglang é‡Œé¢æ²¡æœ‰ï¼Œæˆ‘ä»¥ä¸ºæ˜¯å› æ­¤ sglang å†…å­˜æ³„æ¼äº†ã€‚å®é™…ä¸Šä¸æ˜¯ï¼Œpython è‡ªå·±å°±ä¼šåšè¿™ç§å‡½æ•°å†…çš„å†…å­˜å›æ”¶ï¼Œå®é™…ä¸Š OOM æ˜¯ä» deepspeed engine æ¥çš„ã€‚æˆ‘æŠŠ training batch size å‡å°ï¼Œå°±ä¸ä¼š OOM äº†ã€‚è¿™é‡Œå…¶å®è¿˜æ˜¯å‰é¢æåˆ°çš„é‚£ä¸ªçŒœæƒ³ï¼Œæ˜¯å¦æ˜¯å› ä¸º sglang ç»™å‡ºçš„ token ids çŸ©é˜µæœ‰å¤§å°åŒºåˆ«ï¼Œç›´æ¥å¯¼è‡´äº† OOMï¼Ÿ

### NCCL Hang çš„çŒœæƒ³

å¦‚æˆ‘å‰é¢æ‰€è¿°ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼Œæˆ‘çš„ä¿®æ”¹éƒ½æ˜¯å®Œå…¨ç­‰ä»·çš„ï¼Œå€˜è‹¥ sglang engine å’Œ vllm engine works functionally equivalentï¼Œé‚£ä¹ˆä¸è¯¥æœ‰ä»»ä½•åŒºåˆ«ã€‚ä¸è¿‡ï¼Œæˆ‘åšä¿¡ä¸¤ä¸ªæ¡†æ¶éƒ½æ˜¯æ— æ•°ç”¨æˆ·ä½¿ç”¨åå·²ç»éå¸¸ç¨³å®šçš„äº§å“ï¼Œå·®åˆ«å¤§æ¦‚ç‡æ¥è‡ªæˆ‘æ²¡æœ‰æ³¨æ„åˆ°çš„ä¸ç­‰ä»·æ˜ å°„ï¼Œç‰¹åˆ«æ˜¯ serving params å’Œ sampling params çš„æ˜ å°„ã€‚è¿™é‡Œæ€»ç»“ä¸‹æˆ‘æ‰€æœ‰çš„çŒœæƒ³å’Œ TODOï¼š

1. ç›´æ¥ä¼ å…¥ token ids ç»™ sglangï¼Œä¸è¦å†å¯¹ prompts tokenize ä¸€æ¬¡äº†ã€‚
2. æ‰“å°å‡º tokens çš„å¼€å§‹å’Œç»“å°¾ï¼Œæ£€æŸ¥ vllm å’Œ sglang å¤„ç†ç‰¹æ®Š token æ˜¯å¦æœ‰åŒºåˆ«ã€‚
3. æ‰“å°å‡ºä¼ å…¥ç»™ experience making çš„ tokens çŸ©é˜µå¤§å°ï¼Œéš¾é“äºŒè€…çš„çŸ©é˜µå¤§å°å·®å¼‚ï¼ˆè­¬å¦‚æœ€é•¿çš„ string ç‰¹åˆ«é•¿å¯¼è‡´ padding åå·®å¼‚ç‰¹åˆ«å¤§ï¼‰ä¼šæœ‰æ˜¾è‘—å½±å“ä¹ˆï¼Ÿ
4. æµ‹è¯• main ä¸Šæ˜¯å¦ä¹Ÿä¼šå¡é¡¿ï¼Ÿ
5. æµ‹è¯•æ˜¯å¦æ˜¯ backend çš„é—®é¢˜ï¼Ÿ
6. æ£€æŸ¥ vllm åˆ° sglang çš„å‚æ•°æ˜ å°„æ˜¯å¦æ­£ç¡®ï¼Ÿ
7. åŒæ ·çš„ï¼Œæ£€æµ‹ sampling params æ˜¯å¦æ­£ç¡®ï¼Ÿ
8. æŸ¥çœ‹ cache hit rateï¼Œæ€§èƒ½ä¸Šåº”è¯¥è¿˜æœ‰æå‡ç©ºé—´ã€‚
9. æµ‹è¯•æ˜¯å¦æ˜¯ç¯å¢ƒé—®é¢˜ï¼Œç”šè‡³æ¢ä¸€å°è®¾å¤‡è¯•è¯•ã€‚
10. all_prompt_tokens å’Œ input token ids in engine outputs çš„åŒºåˆ«ã€‚
11. æ‰“å°ä¸‹æ¯ä¸ª training step çš„ input tensor size å’Œ æ—¶é—´ï¼Œæ£€æŸ¥ä¸‹ä¸ºä»€ä¹ˆæœ‰çš„åœ°æ–¹å¡ä¸€ä¸ªå°æ—¶ã€‚

è¿™ä¹ˆå¤šçŒœæƒ³ï¼Œå…¶å® print å°±å¯ä»¥éªŒè¯å¾ˆå¤šï¼Œæ‰€ä»¥æˆ‘æ‰“äº†éå¸¸è¯¦ç»†çš„ logï¼Œç›´æ¥ print åˆ°æŒ‡ç”²ç¼é‡Œé¢ã€‚

## å¯¹æ‹æŒ‡ä»¤

### å¯åŠ¨ ray é›†ç¾¤

<details>
<summary> launch ray</summary>

```bash
al 6

ray stop

ray start --head --node-ip-address 127.0.0.1 --num-gpus 6 --port 1234 --temp-dir=$RAY_TEMP_DIR

pkill -9 -f train_ppo_ray

rm -rf $RLHF_CKPT_DIR/*
```
</details>

### NV 01 100k

<details> 

<summary>  åœ¨ NV 01 çš„ docker ä¸Šä½¿ç”¨ 100k æ ·æœ¬è¿›è¡Œå¯¹æ‹ </summary>

```bash
# conda activate rlhf-sglang

rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.17.0.2:1234" \
--runtime-env-json="{
  \"working_dir\": \"${RLHF_CKPT_DIR}\",
  \"env_vars\": {
    \"PYTHONPATH\": \"/root/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages\"
  }
}" \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend sglang \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path ${RLHF_CKPT_DIR}/examples/checkpoint-sglang-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 32 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 2 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_run_name sglang-$TIME \
   --wandb_project openrlhf >> ~/log/sglang-$TIME.log
```

```bash
# conda activate rlhf-vllm

rlhf-vllm

TIME=$(now)

echo $TIME

ray job submit --address="172.17.0.3:1234" \
   --runtime-env-json='{
     "working_dir": "/root/rlhf-ckpt",
     "env_vars": {
       "PYTHONPATH": "/root/miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages"
     }
   }' \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend vllm \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path /root/rlhf-ckpt/examples/checkpoint-vllm-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 64 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 2 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_project openrlhf \
   --wandb_run_name vllm-$TIME >> ~/log/vllm-$TIME.log
```
</details>

### NV 02 100k

<details> 

<summary> åœ¨ NV 02 ä¸Šç›´æ¥ä½¿ç”¨ 100k æ ·æœ¬è¿›è¡Œå¯¹æ‹ </summary>

```bash
# conda activate rlhf-sglang

rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.31.59.18:1234" \
   --runtime-env-json='{
     "working_dir": "/opt/dlami/nvme/chenyang/rlhf-ckpt",
     "env_vars": {
       "PYTHONPATH": "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages"
     }
   }' \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend sglang \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path /opt/dlami/nvme/chenyang/rlhf-ckpt/examples/checkpoint-sglang-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 64 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 2 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_run_name sglang-$TIME \
   --wandb_project openrlhf >> ~/log/sglang-$TIME.log
```

```bash
# conda activate rlhf-vllm

rlhf-vllm

TIME=$(now)

echo $TIME

ray job submit --address="172.31.59.18:1234" \
   --runtime-env-json='{
     "working_dir": "/opt/dlami/nvme/chenyang/rlhf-ckpt",
     "env_vars": {
       "PYTHONPATH": "/opt/dlami/nvme/chenyang/.miniconda3/envs/rlhf-vllm/lib/python3.11/site-packages"
     }
   }' \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend vllm \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path /opt/dlami/nvme/chenyang/rlhf-ckpt/examples/checkpoint-vllm-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 64 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 2 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_project openrlhf \
   --wandb_run_name vllm-$TIME >> ~/log/vllm-$TIME.log
```

</details>

### NV 01 512

<details>
<summary> åœ¨ NV 01 çš„ docker ä¸Šä½¿ç”¨ 512 ä¸ªæ ·æœ¬è¿›è¡Œå•æµ‹ </summary>

```bash
rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.17.0.2:1234" \
--runtime-env-json="{
  \"working_dir\": \"${RLHF_CKPT_DIR}\",
  \"env_vars\": {
    \"PYTHONPATH\": \"/root/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages\"
  }
}" \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend sglang \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path ${RLHF_CKPT_DIR}/examples/checkpoint-sglang-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 32 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 128 \
   --max_samples 512 \
   --max_epochs 1 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_run_name sglang-$TIME \
   --wandb_project openrlhf >> ~/log/sglang-$TIME.log
```

</details>

### Hyperbolic 100K

<details>
<summary> Hyperbolic 100K çš„æµ‹è¯• </summary>

```bash
rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.27.13.23:1234" \
--runtime-env-json="{
  \"working_dir\": \"${RLHF_CKPT_DIR}\",
  \"env_vars\": {
    \"PYTHONPATH\": \"/data/chayenne/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages\"
  }
}" \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend sglang \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path ${RLHF_CKPT_DIR}/examples/checkpoint-sglang-hyperbolic-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 32 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 2 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_run_name sglang-hyperbolic-$TIME \
   --wandb_project openrlhf >> ~/log/sglang-hyperbolic-$TIME.log
```

```bash
rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.27.13.23:1234" \
--runtime-env-json="{
  \"working_dir\": \"${RLHF_CKPT_DIR}\",
  \"env_vars\": {
    \"PYTHONPATH\": \"/data/chayenne/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages\"
  }
}" \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend vllm \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path ${RLHF_CKPT_DIR}/examples/checkpoint-vllm-hyperbolic-$(now)/llama3-8b-rlhf \
   --save_steps 5 \
   --micro_train_batch_size 8 \
   --train_batch_size 32 \
   --micro_rollout_batch_size 32 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 2 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_run_name vllm-hyperbolic-$TIME \
   --wandb_project openrlhf >> ~/log/vllm-hyperbolic-$TIME.log
```


</details>

### Hyperbolic 100K é»˜è®¤å‚æ•°

<details>
<summary> Hyperbolic 100K é»˜è®¤å‚æ•° </summary>

main ä¸Šé»˜è®¤å‚æ•°

```bash
rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.27.13.23:1234" \
--runtime-env-json="{
  \"working_dir\": \"${RLHF_CKPT_DIR}\",
  \"env_vars\": {
    \"PYTHONPATH\": \"/data/chayenne/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages\"
  }
}" \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path ${RLHF_CKPT_DIR}/examples/checkpoint-vllm-main-$(now)/llama3-8b-rlhf \
   --micro_train_batch_size 4 \
   --train_batch_size 128 \
   --micro_rollout_batch_size 8 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 1 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_project openrlhf \
   --wandb_run_name vllm-main-$TIME >> ~/log/vllm-main-$TIME.log
```

dev pr ä¸Šé»˜è®¤å‚æ•°

```bash
rlhf-sglang

TIME=$(now)

echo $TIME

ray job submit --address="172.27.13.23:1234" \
--runtime-env-json="{
  \"working_dir\": \"${RLHF_CKPT_DIR}\",
  \"env_vars\": {
    \"PYTHONPATH\": \"/data/chayenne/miniconda3/envs/rlhf-sglang/lib/python3.11/site-packages\"
  }
}" \
   -- python3 -m openrlhf.cli.train_ppo_ray \
   --backend sglang \
   --ref_num_nodes 1 \
   --ref_num_gpus_per_node 1 \
   --reward_num_nodes 1 \
   --reward_num_gpus_per_node 1 \
   --critic_num_nodes 1 \
   --critic_num_gpus_per_node 1 \
   --actor_num_nodes 1 \
   --actor_num_gpus_per_node 1 \
   --vllm_num_engines 1 \
   --vllm_tensor_parallel_size 1 \
   --colocate_critic_reward \
   --colocate_actor_ref \
   --pretrain OpenRLHF/Llama-3-8b-sft-mixture \
   --reward_pretrain OpenRLHF/Llama-3-8b-rm-mixture \
   --save_path ${RLHF_CKPT_DIR}/examples/checkpoint-sglang-dev-$(now)/llama3-8b-rlhf \
   --micro_train_batch_size 4 \
   --train_batch_size 128 \
   --micro_rollout_batch_size 8 \
   --rollout_batch_size 1024 \
   --max_samples 100000 \
   --max_epochs 1 \
   --prompt_max_len 1024 \
   --generate_max_len 1024 \
   --zero_stage 3 \
   --bf16 \
   --actor_learning_rate 5e-7 \
   --critic_learning_rate 9e-6 \
   --init_kl_coef 0.01 \
   --prompt_data OpenRLHF/prompt-collection-v0.1 \
   --input_key context_messages \
   --apply_chat_template \
   --packing_samples \
   --normalize_reward \
   --adam_offload \
   --flash_attn \
   --gradient_checkpointing \
   --use_wandb $WANDB_API_KEY \
   --wandb_project openrlhf \
   --wandb_run_name sglang-dev-$TIME >> ~/log/sglang-dev-$TIME.log
```   

</details>

## Debug NCCL Hang
