## èƒŒæ™¯
ç›®å‰çš„ main ä¸Šçš„å¹¶è¡Œå†™æ³•ç­‰ä»·äºé™åˆ¶äº† `tp<=8`ï¼Œä¸ºäº†æ”¯æŒ deepseek ç›¸å…³çš„è®­ç»ƒï¼Œéœ€è¦ verl engine çš„è·¨ node æ”¯æŒã€‚

## Proposal

https://gist.github.com/fzyzcjy/01b851e045b970f16e63580b12dbf7ab

## Step by step setup

**1.** ç™»é™† novita_h20_1

```bash
ssh novita_h20_1
docker exec -it {YOUR CONTAINER NAME} /bin/zsh
```

**2.** å®‰è£… verl-sglang éœ€è¦çš„ä¾èµ–

```bash
apt install python3.10-venv

# åˆ›å»º venv
python3 -m venv .venv --upgrade-deps
source .venv/bin/activate
pip install build wheel

# å®‰è£… SGlang
git clone -b v0.4.4.post3 https://github.com/sgl-project/sglang.git
cd sglang
pip install --upgrade pip
pip install -e "python[all]" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python

# å®‰è£… verl
cd ..
git clone https://github.com/ocss884/verl.git verl-sglang
cd verl-sglang
git switch sglang_multinode
pip install ".[gpu]"
```

**3.** è®¾ç½® Huggingface çš„ç¯å¢ƒå˜é‡

novitaçš„ç£ç›˜ç©ºé—´ä¸å¤§ï¼Œæ³¨æ„ç”¨ä»¥ä¸‹é…ç½®å…±äº«æ¨¡å‹æƒé‡å’Œæ•°æ®é›†æ–‡ä»¶ï¼š

```bash
# Huggingface
export HF_DATASETS_CACHE="/model/shared/.cache/huggingface/datasets"
export HF_HOME="/model/shared/.cached/huggingface"
```

**3.** åœ¨ **novita_h20_1** å¯åŠ¨ ray

```bash
ray start --head --dashboard-host=0.0.0.0
```

è¿è¡Œç»“æŸåä¼šçœ‹åˆ°ä¸‹é¢çš„ä¿¡æ¯ï¼š

<img src=../img/gcs-address.png />

è®°ä½ä¸Šé¢çš„ GCS address

**4.** åœ¨åœ¨ **novita_h20_2** åŠ å…¥ ray cluster

åœ¨ novita_h20_2 é‡å¤ä¸Šé¢çš„ 1-3 é…ç½®å¥½ç¯å¢ƒåï¼Œè¿è¡Œä¸‹é¢çš„å‘½ä»¤ï¼Œä»¤ node2 åŠ å…¥ cluster

```bash
ray start --address='10.94.16.4:6379'
```

çœ‹åˆ°ä¸‹é¢çš„ä¿¡æ¯è¯´æ˜åŠ å…¥æˆåŠŸï¼š

<img src=../img/ray-runtime-start.png />

è¿è¡Œå®Œæ¯•åå›åˆ° novita_h20_1ï¼Œè¿è¡Œï¼š

```bash
ray status
```
å¯ä»¥çœ‹åˆ°æ­¤æ—¶æœ‰ä¸¤ä¸ª node åŠ å…¥äº†ï¼CHEERSï¼

<img width="506" src=../img/multi-node-status.png />

**5.** è¿è¡Œå®éªŒ

å¤šæœºå®éªŒå¯åŠ¨è„šæœ¬ï¼Œæœ¬æ¬¡å®éªŒä½¿ç”¨ Qwen2-7B-Instructï¼Œ2 æœº 4 å¡ã€‚æµ‹è¯•ç¯å¢ƒå¦‚ä¸‹ï¼š

<details>
<summary>torchrun DP=2ï¼ŒTP=2 ï¼ˆè·¨æœºTPï¼‰</summary>
 
```bash
#åœ¨node0ä¸Š
torchrun --nnodes=2 --nproc_per_node=2 --master_addr=<NODE0 IP> --master_port=34567 --node_rank 0 torchrun_verlengine.py
#åœ¨node1ä¸Š
torchrun --nnodes=2 --nproc_per_node=2 --master_addr=<NODE0 IP> --master_port=34567 --node_rank 1 torchrun_verlengine.py
```
</details>

<details>
<summary>verl rollout DP=2ï¼ŒTP=2 ï¼ˆè·¨æœºTPï¼‰</summary>
 
```bash
set -x

gsm8k_train_path=$HOME/data/gsm8k/train.parquet
gsm8k_test_path=$HOME/data/gsm8k/test.parquet

train_files="['$gsm8k_train_path']"
test_files="['$gsm8k_test_path']"

python3 -m verl.trainer.main_ppo \
    data.train_files="$train_files" \
    data.val_files="$test_files" \
    data.train_batch_size=1024 \
    data.max_prompt_length=1024 \
    data.max_response_length=1 \
    data.filter_overlong_prompts=True \
    data.truncation='error' \
    actor_rollout_ref.model.path=Qwen/Qwen2-7B-Instruct \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.optim.lr=1e-6 \
    actor_rollout_ref.model.use_remove_padding=True \
    actor_rollout_ref.actor.ppo_mini_batch_size=256 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8 \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=True \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=16 \
    actor_rollout_ref.rollout.tensor_model_parallel_size=4 \
    actor_rollout_ref.rollout.name=sglang \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=16 \
    actor_rollout_ref.ref.fsdp_config.param_offload=True \
    critic.optim.lr=1e-5 \
    critic.model.use_remove_padding=True \
    critic.model.path=Qwen/Qwen2-7B-Instruct \
    critic.model.enable_gradient_checkpointing=True \
    critic.ppo_micro_batch_size_per_gpu=8 \
    critic.model.fsdp_config.param_offload=True \
    critic.model.fsdp_config.optimizer_offload=True \
    algorithm.kl_ctrl.kl_coef=0.0001 \
    trainer.critic_warmup=0 \
    trainer.logger=['console'] \
    trainer.n_gpus_per_node=2 \
    trainer.nnodes=2 \
    trainer.save_freq=-1 \
    trainer.test_freq=10 \
    trainer.total_epochs=15 $@
```
</details>

<details>
<summary>verl rollout DP=1ï¼ŒTP=4 ï¼ˆå•æœºTPï¼‰</summary>
 
```
set -x

gsm8k_train_path=$HOME/data/gsm8k/train.parquet
gsm8k_test_path=$HOME/data/gsm8k/test.parquet

train_files="['$gsm8k_train_path']"
test_files="['$gsm8k_test_path']"

python3 -m verl.trainer.main_ppo \
    data.train_files="$train_files" \
    data.val_files="$test_files" \
    data.train_batch_size=1024 \
    data.max_prompt_length=1024 \
    data.max_response_length=1 \
    data.filter_overlong_prompts=True \
    data.truncation='error' \
    actor_rollout_ref.model.path=Qwen/Qwen2-7B-Instruct \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.optim.lr=1e-6 \
    actor_rollout_ref.model.use_remove_padding=True \
    actor_rollout_ref.actor.ppo_mini_batch_size=256 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8 \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=True \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=16 \
    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
    actor_rollout_ref.rollout.name=sglang \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=16 \
    actor_rollout_ref.ref.fsdp_config.param_offload=True \
    critic.optim.lr=1e-5 \
    critic.model.use_remove_padding=True \
    critic.model.path=Qwen/Qwen2-7B-Instruct \
    critic.model.enable_gradient_checkpointing=True \
    critic.ppo_micro_batch_size_per_gpu=8 \
    critic.model.fsdp_config.param_offload=True \
    critic.model.fsdp_config.optimizer_offload=True \
    algorithm.kl_ctrl.kl_coef=0.0001 \
    trainer.critic_warmup=0 \
    trainer.logger=['console'] \
    trainer.n_gpus_per_node=2 \
    trainer.nnodes=2 \
    trainer.save_freq=-1 \
    trainer.test_freq=10 \
    trainer.total_epochs=15 $@
```
</details>

æ³¨ï¼šverl rolloutå‡å¯ç›´æ¥ä½¿ç”¨`multinode_sglang.sh`æ–‡ä»¶æ¥æµ‹è¯•

## å¸¸è§é—®é¢˜

**1.** `pip install .[sglang]` å¤±è´¥  
   è¿™é‡Œé”™è¯¯ç§ç±»å¾ˆå¤šï¼Œä¸å…¨éƒ¨åˆ—ä¸¾ï¼Œåªå†™å‡ ä¸ªæˆ‘å°è±¡æ¯”è¾ƒæ·±çš„é”™è¯¯ï¼š
  - Cargo ä¸å­˜åœ¨
  - pip resolve deps è€—æ—¶ç‰¹åˆ«ä¹…åçªç„¶ fail  
  ...

è¯·è¿è¡Œä¸‹é¢çš„å‘½ä»¤å°†ä½ çš„ `pip` å‡çº§åˆ°æœ€æ–°çš„ `25.0.1`ã€‚ç›®å‰ä½¿ç”¨æ—§ç‰ˆï¼ˆå¦‚ py3.10 è‡ªå¸¦çš„ pip==22.0ï¼‰å®‰è£… verl-sglang å¯èƒ½ä¼šå‡ºç° pip æ— æ³•æ­£ç¡®è§£æä¾èµ–çš„æƒ…å†µï¼š

```bash
pip install --upgrade pip
```

## Debugè®°å½•ï¼ˆpriority 1-5ï¼‰
- [x] `CUDA initialization: Unexpected` error from cudaGetDeviceCount() (**5**)

`CUDA_VISIBLE_DEVICES`ä¸åˆæ³•çš„è®¾ç½®å¯¼è‡´ï¼Œæ³¨æ„æ£€æŸ¥sglang_rollouté‡Œæ›¿æ¢`CUDA_VISIBLE_DEVICES`æ—¶æ˜¯å¦ä¼šall gatherå‡ºå¦‚`0,1,0,1`è¿™ç§ä¸åˆæ³•çš„å€¼

- [ ] `VerlEngine`æ— æ³•å¯åŠ¨`deepseek-ai/deepseek-llm-7b-chat` (**4**)

[æ¨¡å‹ç»“æ„](https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat/blob/main/config.json)å…¶å®å°±æ˜¯`Llama`ï¼Œæˆ‘(linjunrong)å·²ç»å°è¯•è¿‡
- python -m sglang.launch_server --tp 4 --model-path deepseek-ai/deepseek-llm-7b-chat --host 0.0.0.0
- engine = Engine(model_path="deepseek-ai/deepseek-llm-7b-chat", tp_size=4, node_rank=0, nnodes=1)

äºŒè€…å‡å¯ä»¥æˆåŠŸï¼Œéœ€è¦æ£€æŸ¥ä¸€ä¸‹verlengineä½¿ç”¨ä»€ä¹ˆçš„é¢å¤–å‚æ•°å¯¼è‡´äº†ä¸‹é¢çš„æŠ¥é”™ã€‚[related issue](https://github.com/pytorch/pytorch/issues/145168) from youkaichao
<details>
 <summary>error</summary>
 
```shell
[2025-04-01 23:22:06 TP1] Scheduler hit an exception: Traceback (most recent call last):
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/managers/scheduler.py", line 1999, in run_scheduler_process
    scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/managers/scheduler.py", line 249, in __init__
    self.tp_worker = TpWorkerClass(
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/managers/tp_worker_overlap_thread.py", line 63, in __init__
    self.worker = TpModelWorker(server_args, gpu_id, tp_rank, dp_rank, nccl_port)
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
    self.model_runner = ModelRunner(
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_executor/model_runner.py", line 169, in __init__
    self.initialize(min_per_gpu_memory)
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_executor/model_runner.py", line 179, in initialize
    self.load_model()
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_executor/model_runner.py", line 392, in load_model
    self.model = get_model(
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
    return loader.load_model(
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_loader/loader.py", line 370, in load_model
    model.load_weights(self._get_all_weights(model_config, model))
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/models/llama.py", line 481, in load_weights
    for name, loaded_weight in weights:
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_loader/loader.py", line 343, in _get_all_weights
    yield from self._get_weights_iterator(primary_weights)
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_loader/loader.py", line 329, in <genexpr>
    return ((source.prefix + name, tensor) for (name, tensor) in weights_iterator)
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/sglang/srt/model_loader/weight_utils.py", line 460, in pt_weights_iterator
    torch.cuda.empty_cache()
  File "/data/gpu-use/verl-sglang/.venv/lib/python3.10/site-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: captures_underway.empty() INTERNAL ASSERT FAILED at "../c10/cuda/CUDACachingAllocator.cpp":2967, please report a bug to PyTorch.
```
</details>

<details>
 <summary>sglang.check_env</summary>
 
 ```bash
 Python: 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA H800
GPU 0,1,2,3 Compute Capability: 9.0
CUDA_HOME: /data/cuda/cuda-12.4/cuda
NVCC: Cuda compilation tools, release 12.4, V12.4.131
CUDA Driver Version: 535.129.03
PyTorch: 2.5.1+cu124
sglang: 0.4.4.post3
sgl_kernel: 0.0.5.post4
flashinfer: Module Not Found
triton: 3.1.0
transformers: 4.50.0
torchao: 0.9.0
numpy: 2.2.4
aiohttp: 3.11.14
fastapi: 0.115.12
hf_transfer: 0.1.9
huggingface_hub: 0.30.0
interegular: 0.3.3
modelscope: 1.24.1
orjson: 3.10.16
outlines: 0.1.11
packaging: 24.2
psutil: 7.0.0
pydantic: 2.11.1
multipart: Module Not Found
zmq: Module Not Found
uvicorn: 0.34.0
uvloop: 0.21.0
vllm: Module Not Found
xgrammar: 0.1.17
openai: 1.69.0
tiktoken: 0.9.0
anthropic: 0.49.0
litellm: 1.65.0
decord: 0.6.0
NVIDIA Topology: 
	[4mGPU0	GPU1	GPU2	GPU3	NIC0	NIC1	NIC2	NIC3	NIC4	NIC5	NIC6	NIC7	NIC8	NIC9	NIC10	NIC11	NIC12	NIC13	NIC14	NIC15	NIC16	CPU Affinity	NUMA Affinity	GPU NUMA ID[0m
GPU0	 X 	NV8	NV8	NV8	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS				N/A
GPU1	NV8	 X 	NV8	NV8	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS				N/A
GPU2	NV8	NV8	 X 	NV8	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS				N/A
GPU3	NV8	NV8	NV8	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX				N/A
NIC0	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS				
NIC1	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS				
NIC2	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS				
NIC3	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS				
NIC4	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS				
NIC5	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS				
NIC6	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS				
NIC7	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS				
NIC8	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX				
NIC9	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS	SYS				
NIC10	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS	SYS				
NIC11	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS	SYS				
NIC12	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS	SYS				
NIC13	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS	SYS				
NIC14	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS	SYS				
NIC15	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 	SYS				
NIC16	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	SYS	PIX	SYS	SYS	SYS	SYS	SYS	SYS	SYS	 X 				

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks

NIC Legend:

  NIC0: mlx5_0
  NIC1: mlx5_1
  NIC2: mlx5_2
  NIC3: mlx5_3
  NIC4: mlx5_4
  NIC5: mlx5_5
  NIC6: mlx5_6
  NIC7: mlx5_7
  NIC8: mlx5_8
  NIC9: mlx5_9
  NIC10: mlx5_10
  NIC11: mlx5_11
  NIC12: mlx5_12
  NIC13: mlx5_13
  NIC14: mlx5_14
  NIC15: mlx5_15
  NIC16: mlx5_16


ulimit soft: 524288

 ```
</details>

<details>
 <summary>å¤ç°è„šæœ¬ï¼Œå•æœº DP=1 TP=4 </summary>
 
 1. å°†`torchrun_verlengine.py`çš„`== Parallel ==`éƒ¨åˆ†æ”¹ä¸º
 ```
 dp, tp, pp = 1, 4, 1
 device_count = 4
 model_name = "deepseek-ai/deepseek-llm-7b-chat"
 ```
 
 2.è¿è¡Œä¸‹é¢çš„å‘½ä»¤
 ```bash
 torchrun --nnodes=1 --nproc_per_node=4 --master_addr=<NODE0 IP> --master_port=34567 torchrun_verlengine.py
 ```
</details>

- [ ] `[torch_memory_saver.cpp] CUresult error  result=2 file=csrc/torch_memory_saver.cpp func=cu_mem_create line=103` (**5**)

```bash
ValueError: TP rank 0 could finish the model loading, but there are other ranks that didn't finish loading. It is likely due to unexpected failures (e.g., OOM) or a slow node
```

 1. å°†`torchrun_verlengine.py`ä¸­`== Parallel ==`éƒ¨åˆ†æ”¹ä¸º
```
dp, tp, pp = 1, 8, 1
device_count = 8
model_name = "moonshotai/Moonlight-16B-A3B-Instruct"
```

 2.è¿è¡Œä¸‹é¢çš„å‘½ä»¤
 ```bash
 torchrun --nnodes=1 --nproc_per_node=8 --master_addr=<NODE0 IP> --master_port=34567 torchrun_verlengine.py
 ```

æµ‹è¯•ä½¿ç”¨çš„æœˆæš—å®¶ç”¨äº†deepseekV3ç»“æ„çš„å°æ¨¡å‹ï¼Œçœ‹èµ·æ¥memory saverå’ŒdeepseekV3ç»“æ„å­˜åœ¨ä¸€å®šå†²çªï¼Œå½“å‰ä¼˜å…ˆçº§æœ€é«˜çš„äº‹é¡¹
